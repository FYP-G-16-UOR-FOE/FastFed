import collections
import copy
import os
import pickle
import time
from collections import Counter

import matplotlib.pyplot as plt
import numpy as np
import psutil
import requests
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from torch.utils.data import DataLoader
from torchvision import transforms

import wandb

torch.backends.cudnn.benchmark = True

class Server:
    def __init__(self, device, global_model, model_type, fl_rounds, num_clients, num_selected_clients, local_epochs, selected_algorithm, results_save_dir):
        """
        Server class for Federated Learning aggregation and coordination.
        """
        self.global_model = global_model
        self.device = device
        self.clients = {
            "clients_ids": [],
            "client_api_urls": [],
            "selected_clients_ids": [],
            "selected_clients_models": []
        }
        self.fl_train_config = {
            "fl_rounds": fl_rounds,
            "local_epochs": local_epochs,
            "model_type": model_type,
            "num_clients": num_clients,
            "num_selected_clients": num_selected_clients,
            "results_save_dir": results_save_dir,
            "is_use_full_dataset": True,
        }
        self.fl_accuracy = {
            "selected_algorithm": selected_algorithm,
            "iid_agg_weights": [],
            "accuracy_based_agg_weights": [],
        }
        self.fl_security = {}
        self.fl_performance ={
            "selected_performance_optimization_types": []
        }
        self.history = {
            "global_accuracy": [],
            "global_loss": [],
            "fl_train_time": [],
            "round_local_training_time": [],
            "round_aggregation_time": [],
            "iid_agg_weights_calc_time": [],
            "system_usage": [],
            "round_communication_time": [],
            "round_global_model_send_time": [],
            "round_client_model_recv_time": [],
            "round_global_model_size_bytes": [],
            "global_model_size_bytes": [],
        }
        
        # Global test dataset (CIFAR-10)
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.4914, 0.4822, 0.4465),
                                 (0.2023, 0.1994, 0.2010))
        ])
        global_test_dataset = torchvision.datasets.CIFAR10(
            root='./data', train=False, download=True, transform=transform)
        self.global_test_dataloader = DataLoader(global_test_dataset, batch_size=100)

    def register(self, client_id: int, client_api_url: str):
        if self.fl_train_config["clients_ids"].index(client_id):
            print(f"Client ID: {client_id} already registered.")
            return
        print(f"Registering Client ID: {client_id}")
        self.fl_train_config["clients_ids"].append(client_id)
        self.fl_train_config["client_api_urls"].append(client_api_url)

    # ============================================================
    # ðŸ”¹ Core Server Functions
    # ============================================================
    def get_global_model_params(self):
        """Return global model parameters."""
        return self.global_model.state_dict()
    
    def serialize_model(self, model):
        """
        Convert a PyTorch model's state_dict into a JSON-serializable dictionary.
        Tensors are converted to CPU NumPy arrays, then to Python lists.
        """
        state_dict = model.state_dict()
        serialized = {
            k: (v.detach().cpu().numpy().tolist() if isinstance(v, torch.Tensor) else v)
            for k, v in state_dict.items()
        }
        return serialized
    
    def deserialize_model(self, serialized_state):
        """
        Convert a JSON-serializable model dictionary back into a PyTorch state_dict.
        Lists â†’ Tensors
        Scalars â†’ Tensors
        """
        deserialized_state = {}

        for k, v in serialized_state.items():
            # Case 1: list (weights/bias tensors)
            if isinstance(v, list):
                deserialized_state[k] = torch.tensor(v)

            # Case 2: scalar numpy values that were converted using .item()
            elif isinstance(v, (int, float)):
                deserialized_state[k] = torch.tensor(v)

            # Case 3: fallback (should not happen normally)
            else:
                deserialized_state[k] = torch.tensor(v)

        return deserialized_state

    
    def cal_size(self, obj):
        """Calculate the size of a Python object in bytes."""
        return len(pickle.dumps(obj))
    
    def fed_avg(self, weights_list):
        """
        Perform standard FedAvg aggregation on a list of parameter OrderedDicts (with NumPy arrays as values).
        Returns an OrderedDict of PyTorch tensors.
        """
        avg_params = collections.OrderedDict()
        for key in weights_list[0].keys():
            stacked = np.stack([w[key] for w in weights_list])
            avg_params[key] = torch.from_numpy(np.mean(stacked, axis=0))
        return avg_params

    def weighted_fed_avg(self, weights_list, agg_weights):
        """
        Perform weighted FedAvg aggregation on a list of parameter OrderedDicts (NumPy arrays as values) and weights.
        Returns an OrderedDict of PyTorch tensors.
        """
        total_weight = sum(agg_weights)
        avg_params = collections.OrderedDict()
        for key in weights_list[0].keys():
            stacked = np.stack([w[key] * agg_weights[i] for i, w in enumerate(weights_list)])
            avg_params[key] = torch.from_numpy(np.sum(stacked, axis=0) / total_weight)
        return avg_params

    def aggregate_models(self, client_models=None, agg_weights=None):
        """
        Aggregate client models using FedAvg or Weighted FedAvg, Flower-style (NumPy conversion).
        Accepts a list of client model state_dicts (PyTorch) in client_models.
        """
        if client_models is None:
            client_models = self.selected_clients_models
        # Convert PyTorch state_dicts to OrderedDicts of NumPy arrays
        weights_list = []
        for client_model in client_models:
            state_dict = client_model.state_dict() if hasattr(client_model, "state_dict") else client_model
            weights_np = collections.OrderedDict()
            for k, v in state_dict.items():
                if isinstance(v, torch.Tensor):
                    weights_np[k] = v.cpu().numpy()
                else:
                    weights_np[k] = np.array(v)
            weights_list.append(weights_np)

        # Select aggregation function
        if not agg_weights or (len(agg_weights) > 0 and all(abs(agg_weights[i] - agg_weights[0]) < 1e-6 for i in range(len(agg_weights)))):
            print("\nðŸŸ¢ Using FedAvg aggregation.")
            aggregated_model_params = self.fed_avg(weights_list)
        else:
            print("\nðŸŸ¡ Using Weighted FedAvg aggregation.")
            print("Aggregation Weights :", agg_weights)
            aggregated_model_params = self.weighted_fed_avg(weights_list, agg_weights)
        self.global_model.load_state_dict(copy.deepcopy(aggregated_model_params))

    def cal_min_max_agg_weight(self, client_iid_measure_list):
        """Convert IID measure values into normalized aggregation weights."""
        d_min, d_max = min(client_iid_measure_list), max(client_iid_measure_list)
        if d_max == d_min:
            return [1.0 for _ in client_iid_measure_list]
        agg_weights = [(1 - (val - d_min) / (d_max - d_min)) for val in client_iid_measure_list]
        total = sum(agg_weights)
        return [w / total for w in agg_weights]
    
    def test_model(self):
        """Evaluate global model on test data."""
        self.global_model.eval()
        correct, total, total_loss = 0, 0, 0.0

         # Select loss function
        if self.fl_train_config["model_type"] == "VGG":
            criterion = F.nll_loss
        elif self.fl_train_config["model_type"] == "NormalCNN":
            criterion = nn.CrossEntropyLoss()
        else:
            raise ValueError(f"Invalid model type: {self.model_type}.")

        with torch.no_grad():
            for images, labels in self.global_test_dataloader:
                images, labels = images.to(self.device), labels.to(self.device)
                outputs = self.global_model(images)
                loss = criterion(outputs, labels)
                total_loss += loss.item() * images.size(0)
                correct += (outputs.argmax(dim=1) == labels).sum().item()
                total += labels.size(0)
        avg_loss = total_loss / total
        accuracy = 100.0 * correct / total
        return accuracy, avg_loss

    def evaluate_kmeans_silhouette(self, distribution_matrix, k_range):
        """
        Evaluate silhouette scores for a range of cluster counts.
        """
        silhouette_scores = []
        for k in k_range:
            kmeans = KMeans(n_clusters=k, random_state=0)
            labels = kmeans.fit_predict(distribution_matrix)
            score = silhouette_score(distribution_matrix, labels)
            silhouette_scores.append(score)
            print(f"k={k}, silhouette score={score:.4f}")
        return silhouette_scores

    def get_clients_classification_agg_weights(self, clients):
        """
        Determine the optimal number of client clusters (k) using silhouette score.
        """

        client_dicts = [
            client.get_from_client(data={'agg_weight_type': "cafa"}, comm_type="GET_AGG_WEIGHT")
            for client in clients
        ]
        keys = sorted(client_dicts[0].keys())
        distribution_matrix = np.array([[d[k] for k in keys] for d in client_dicts], dtype=float)

        k_range = range(2, len(clients))  # test from 2 to N-1
        silhouette_scores = self.evaluate_kmeans_silhouette(distribution_matrix, k_range)

        # Plot results
        plt.figure(figsize=(8, 5))
        plt.plot(k_range, silhouette_scores, marker='o')
        plt.title("Silhouette Score vs Number of Clusters (k)")
        plt.xlabel("Number of clusters (k)")
        plt.ylabel("Silhouette Score")
        plt.xticks(k_range)
        plt.grid(True)
        plt.show()

        # Select best k
        best_k_idx = int(np.argmax(silhouette_scores))
        best_k = list(k_range)[best_k_idx]
        print(f"\nOptimal k = {best_k}, Silhouette Score = {silhouette_scores[best_k_idx]:.4f}")

        # Cluster clients
        kmeans = KMeans(n_clusters=best_k, random_state=0)
        client_cluster_labels = kmeans.fit_predict(distribution_matrix)

        num_clients = len(client_cluster_labels)
        cluster_counts = Counter(client_cluster_labels)
        clients_clus_agg_weights = np.array([
            cluster_counts[label] / num_clients for label in client_cluster_labels
        ])

        return clients_clus_agg_weights

    def get_system_usage(self, device):
        usage = {
            "cpu_percent": psutil.cpu_percent(),
            "ram_percent": psutil.virtual_memory().percent,
        }
        if "cuda" in str(device):
            usage.update({
                "gpu_mem_allocated_MB": torch.cuda.memory_allocated(0) / 1e6,
                "gpu_mem_reserved_MB": torch.cuda.memory_reserved(0) / 1e6,
            })
        return usage

    def save_results(self, results, results_save_dir):
        # Build file paths
        results_file = os.path.join(results_save_dir, "results.pkl")

        # Ensure folders exist
        os.makedirs(results_save_dir, exist_ok=True)

        # Save history in one file
        with open(results_file, "wb") as f:
            pickle.dump(results, f)

        print(f"âœ… All result saved successfully.")


    def get_avg_val_accuracy_based_agg_weights(self, selected_clients_models, selected_clients):
        """
        Calculate accuracy-based aggregation weights.
        """
        accuracy_based_agg_weights = []
        for i in range(len(selected_clients)):
            client_model = selected_clients_models[i]
            client_weighted_val_accuracies = []
            for j in range(len(selected_clients)):
                if i == j:
                    continue
                test_client = selected_clients[j]

                get_weighted_val_acc_comm_data = {
                    "client_model": client_model,
                    "model_type": self.model_type,
                }
                client_weighted_val_accuracy = test_client.get_from_client(data=get_weighted_val_acc_comm_data, comm_type="GET_WEIGHTED_VALIDATION_ACCURACY")
                client_weighted_val_accuracies.append(client_weighted_val_accuracy)
            average_client_weighted_val_accuracy = np.mean(client_weighted_val_accuracies)
            accuracy_based_agg_weights.append(average_client_weighted_val_accuracy)

        return accuracy_based_agg_weights

    # ============================================================
    # Federated Learning Coordinator
    # ============================================================
    def start_federated_learning(self):
        # Start Timer
        total_training_start = time.time()
        rng = np.random.default_rng(42)

        # IID Based Aggregation Weights
        if self.fl_accuracy["selected_algorithm"] == "(1-JSD)":
            print("Calculating IID Aggregation Weights")
            for cid in self.fl_train_config["clients_ids"]:
                client_send_iid_measure_url = self.clients["client_api_urls"][cid] + "/send/iid-measure"
                iid_agg_weights = []
                try:
                    response = requests.get(
                        client_send_iid_measure_url,
                        json={"selected_algorithm": self.fl_accuracy["selected_algorithm"]},
                        timeout=None
                    )
                    response.raise_for_status()
                    iid_measure_result = response.json()
                    iid_agg_weight = iid_measure_result['iid_agg_weights']
                    iid_agg_weights_cal_time = iid_measure_result['iid_agg_weights_cal_time']
                    iid_agg_weights.append(iid_agg_weight)
                    self.history["iid_agg_weights_cal_time"].append(iid_agg_weights_cal_time)
                    print(f"âœ“ Received IID measure from Client {cid}")
                except Exception as e:
                    print(f"Failed to receive IID measure from Client {cid}: {e}")
            print("IID Aggregation Weights: ", iid_agg_weights)
        else:
            iid_agg_weights = None
            iid_agg_weights_cal_time = 0.0



        # Federated Learning Rounds
        for fl_round in range(self.fl_train_config["fl_rounds"]):
            print(f"\n{'='*80}\n FEDERATED LEARNING ROUND {fl_round + 1}/{self.fl_train_config["fl_rounds"]}\n{'='*80}")
            round_start_time = time.time()
            
            # Select clients
            selected_clients = rng.choice(self.clients["clients_ids"], size=self.fl_train_config["num_selected_clients"], replace=False)
            self.clients["selected_clients_ids"] = list(selected_clients)
            self.clients["selected_clients_models"] = {cid: [] for cid in selected_clients}

            # Serialize global model
            global_model_json = self.serialize_model(self.global_model)
            model_size_bytes = self.cal_size(global_model_json)
            self.history["global_model_size_bytes"].append(model_size_bytes)
            print(f"Global model size: {model_size_bytes / 1e6:.4f} MB")

            round_global_send_time = 0.0
            round_local_train_time = 0.0
            round_global_recv_time = 0.0

            print(f"Selected clients: {selected_clients}")

            for cid in selected_clients:
                print(f"{'='*80}\nClient {cid} Local Training\n{'='*80}")

                # Client API URL
                client_receive_global_model_url = self.clients["client_api_urls"][cid] + "/receive/global-model"
                client_start_local_training_url = self.clients["client_api_urls"][cid] + "/start/local-training"
                client_send_trained_model_url = self.clients["client_api_urls"][cid] + "/send/trained-model"

                print("Api Url: ", client_receive_global_model_url)
                print("Api Url: ", client_start_local_training_url)
                print("Api Url: ", client_send_trained_model_url)

                # Send the global model to the client
                time_ref = time.time()
                try:
                    response = requests.post(
                        client_receive_global_model_url, 
                        json={"client_id": int(cid), "global_model": global_model_json, "model_type": self.fl_train_config["model_type"]}, 
                        timeout=None
                    )
                    response.raise_for_status()
                    send_duration = time.time() - time_ref 
                    print(f"âœ“ Sent global model to Client {cid} in {send_duration:.4f} sec")

                    round_global_send_time = round_global_send_time + send_duration

                except Exception as e:
                    send_duration = time.time() - time_ref
                    print(f"Failed to send global model to Client {cid} after {send_duration:.4f} sec: {e}")
                    raise Exception

                # Start Client local training
                try:
                    response = requests.post(
                        client_start_local_training_url, 
                        json={
                            "client_id": int(cid),
                            "epochs": self.fl_train_config["local_epochs"],
                            "selected_algorithm": self.fl_accuracy["selected_algorithm"],
                            "is_use_full_dataset": self.fl_train_config["is_use_full_dataset"],
                            "model_type": self.fl_train_config["model_type"],
                            "performance_optimization_types": self.fl_performance["selected_performance_optimization_types"],
                        }, 
                        timeout=None
                    )
                    response.raise_for_status()
                    print(f"âœ“ Started local training for Client {cid}")
                except Exception as e:
                    print(f"Failed to start local training for Client {cid}: {e}")
                    raise Exception

                # Receive the trained model from the client
                time_ref = time.time()
                try:
                    response = requests.get(
                        client_send_trained_model_url, 
                        json={"client_id": int(cid)},
                        timeout=None
                    )
                    response.raise_for_status()
                    client_result = response.json()
                    recv_duration = time.time() - time_ref
                    round_global_recv_time = round_global_recv_time + recv_duration
                    client_model_params = client_result['trained_model']
                    train_duration = client_result['training_duration']
                    self.clients["selected_clients_models"][cid].append(self.deserialize_model(client_model_params))
                    round_local_train_time = round_local_train_time + train_duration
                    print(f"âœ“ Received trained model from Client {cid} in {recv_duration:.4f} sec")
                except Exception as e:
                    print(f"Failed to receive trained model from Client {cid}: {e}")
                    raise Exception

                

            # Record communication times
            self.history["round_global_model_send_time"].append(round_global_send_time)
            self.history["round_client_model_recv_time"].append(round_global_recv_time)
            self.history["round_local_training_time"].append(round_local_train_time)
            self.history["round_communication_time"].append(round_global_send_time + round_global_recv_time)
            

            # Accuracy Based Aggregation Weights
            acc_based_agg_weights = []
            if self.fl_accuracy["selected_algorithm"] == "AccuracyBased" or self.fl_accuracy["selected_algorithm"] == "AccuracyBased(1-JSD)" or self.fl_accuracy["selected_algorithm"] == "AccuracyBased_SEBW":
                print("Calculating Accuracy Based Aggregation Weights")
                for cid in selected_clients:
                    test_client_model_params = self.clients["selected_clients_models"][cid]
                    for t_cid in selected_clients:
                        if cid == t_cid:
                            continue
                        client_send_acc_based_measure_url = self.clients["client_api_urls"][cid] + "/send/acc-based-measure"
                        try:
                            response = requests.get(
                                client_send_acc_based_measure_url,
                                json={
                                    "client_model_params": test_client_model_params,
                                    "model_type": self.fl_train_config["model_type"],
                                },
                                timeout=None
                            )
                            response.raise_for_status()
                            acc_based_measure_result = response.json()
                            acc_based_agg_weights.append(acc_based_measure_result['acc_based_measure'])

                            print(f"âœ“ Received Accuracy Based measure from Client {cid}")
                        except Exception as e:
                            print(f"Failed to receive Accuracy Based measure from Client {cid}: {e}")
            else:
                acc_based_agg_weights = None
                        
            # Get Aggregation Weights
            if iid_agg_weights and acc_based_agg_weights:
                print("IID Measure Weights: ", iid_agg_weights)
                print("Accuracy Based Weight: ", acc_based_agg_weights)
                client_agg_weights = [
                    iid_agg_weights[cid] * acc_based_agg_weights[i] for i, cid in enumerate(selected_clients)
                ]
                print("Combined Weights: ", client_agg_weights)
            elif iid_agg_weights:
                print("IID Measure Weights: ", iid_agg_weights)
                client_agg_weights = [iid_agg_weights[cid] for cid in selected_clients]
            elif acc_based_agg_weights:
                print("Accuracy Based Weight: ", acc_based_agg_weights)
                client_agg_weights = [acc_based_agg_weights[i] for i in range(len(selected_clients))]
            else:
                client_agg_weights = None

            # Evaluate Global Model
            acc, loss = self.test_model()
            self.history["global_accuracy"].append(acc)
            self.history["global_loss"].append(loss)
            round_time = time.time() - round_start_time
            self.history["fl_train_time"].append(round_time)
            system_usage = self.get_system_usage(self.device)
            self.history["system_usage"].append(system_usage)

            print(f"Round {fl_round+1}: Accuracy={acc:.2f}%, Loss={loss:.4f}")

            wandb.log({
                "fl_rounds": fl_round + 1,
                "global_accuracy": acc,
                "global_loss": loss,
                "round_communication_time": self.history["round_communication_time"][-1],
                "round_global_model_send_time": self.history["round_global_model_send_time"][-1],
                "round_client_model_recv_time": self.history["round_client_model_recv_time"][-1],
                "round_local_training_time": self.history["round_local_training_time"][-1],
                "round_aggregation_time": self.history["round_aggregation_time"][-1],
                "round_dequantization_time": 0,
                "round_total_time": self.history["fl_train_time"][-1],
                "cpu_percent": system_usage["cpu_percent"],
                "ram_percent": system_usage["ram_percent"],
                **({k: v for k, v in system_usage.items() if "gpu" in k}),
            })
                
        print(f"\nFederated Learning Completed in {(time.time()-total_training_start)/60:.2f} minutes!")

        # ðŸ§¾ Save results
        self.save_results(results=self.history, results_save_dir=self.fl_train_config["results_save_dir"])
        
        # Finish the WANDB
        wandb.finish()